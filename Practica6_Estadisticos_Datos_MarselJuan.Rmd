---
title: "Práctica 6. Análisis Exploratorio de Datos."
subtitle: "Análisis Exploratorio de Datos, Máster en Ciencia de Datos - UV"
output:
  html_document:
    echo: yes
    number_sections: no
    theme: lumen
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# CONFIGURACIÓN GENERAL
library(knitr)
options(width = 100)
# Opciones generales chunks
opts_chunk$set(echo = T, message = F, error = F, warning = F,
               comment = NA, fig.align = 'center', dpi = 100, tidy = F,
               cache.path = '.cache/', fig.path = './figure/', fig.dim=c(4,3))
# options(xtable.type = 'html')
knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
# knit_hooks$set(plot = knitr:::hook_plot_html)
opts_chunk$set(fig.width=6, fig.height=4)
```

```{r}

rm(list=ls())
library(pacman)
packages = c("knitr", "ggplot2","tidyr","dplyr","readr","GGally","dplyr")
pacman::p_load(char=packages)

```

# Introducción y objetivos

El objetivo de esta práctica es realizar un análisis exploratorio de datos: explorando el conjunto de datos; obteniendo los estadísticos básicos de las variables numéricas; visualizando las relaciones entre variables; y calculando las relaciones entre variables tanto numéricas como categóricas.

En esta práctica, las etapas que vamos a considerar en el análisis exploratorio de datos son:

  1. Lectura e inspección de los datos.
  2. Análisis univariante de los datos: variables numéricas y categóricas.
  3. Análisis bivariante de los datos: variables numéricas y categóricas.
  
# Lectura e inspección de los datos

Vamos a trabajar con el conjunto de datos "Nos Autoevaluamos" generado por nosotros al rellenar la tabla de datos de la tarea correspondiente. 

Este conjunto contiene datos perdidos e inconsistencias que habrá que corregir antes de analizar la distribución de los datos. Para evitar estas inconsistencias, estos datos deberán ser eliminados, corregidos o imputados, tal y como vimos en la práctica anterior.

El conjunto "`NosAutoanalizamos_TD2019 - Hoja 1 - Clean.tsv`" ya ha sido procesado en parte para poder trabajar en esta práctica. En él tenemos para cada una de las asignaturas (ALG, ANM, FP, DCS y MD) columnas acabadas en `.num`, con las notas en valor numérico, y columnas acabadas en `.cat`, con valores categóricos: AP para aprobada, NP para no presentado y NC para no compensable.

Variable | Comentarios
---------|-------------------------------------------------------------
Identificación  | Usuario de correo
Age  |	Edad en años
Sex  |	Sexo: 'Femenino', 'Masculino'	
Wr.Hnd  |	Distancia del extremo del índice al extremo del pulgar en centímetros de la mano con la que escribimos
NW.Hnd  |	Mano con la que escribes: 'Izquierda', 'Derecha'	
Fold  |	Brazo que está arriba cuando cruzas los brazos: 'Izquierdo', 'Derecho'
Pulse  |	Ritmo cardíaco, en reposo, en latidos por minuto.	
Clap  |	Posición de las manos al aplaudir: 'Der s Izd', (Derecha sobre izquierda) 'Izq s Der', 'Ninguna'	
Exer  |	Días a la semana que realizas ejercicio físico: Numérica de 0-7
Smoke  |	Fumador: 'Sí' / 'No'	
Height  |	Altura expresada en centímetros	
ALG  |	Calificación obtenida en álgebra. Usa 'NP' para no presentado y 'NC', para no compensable, si procede	
ANM  |	Calificación obtenida en análisis matemático. Usa 'NP' para no presentado y 'NC', para no compensable, si procede	
FP  |	Calificación obtenida en fundamentos de programación. Usa 'NP' para no presentado y 'NC', para no compensable, si procede	
DCS  |	Calificación obtenida en Datos Ciencia y Sociedad. Usa 'NP' para no presentado y 'NC', para no compensable, si procede	
MD  |	Calificación obtenida en Matemática Discreta. Usa 'NP' para no presentado y 'NC', para no compensable, si procede	
HSt  |	Horas de trabajo diarias relacionadas con los estudios, además de la asistencia a clase
Hwork  |	Horas de trabajo remunerado semanales (0 indica que no tiene otro trabajo)	
Comentarios  |  Campo de texto libre para incluir comentarios que consideres sobre la asignatura

## Ejercicio 1: Lectura de datos

  - Lee los datos del fichero con `read_tsv` a una variable llamada `Datos`.
  - Convierte las variables categóricas acabadas en `.cat` a tipo `factor`. Puedes hacerlo:
     Usando la función `mutate_at`  (junto con `vars`, `ends_with` y `as.factor`).
     Usando `mutate(across())` (junto con `ends_with` y `as.factor`).

```{r Solucion_Ej1, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}

Datos <- read_tsv("data/NosAutoanalizamos_TD2019 - Hoja 1 - Clean.tsv")

# 2. Convierte las variables categóricas acabadas en .cat a tipo factor
Datos <- Datos %>%
  mutate(across(ends_with(".cat"), as.factor))

# Las variables .cat ahora deberían aparecer como <fct> (factor)
glimpse(Datos)

```

## Ejercicio 2: Inspección visual

Inspecciona visualmente los valores del conjunto de datos (`View`) y ordena de mayor a menor y de menor a mayor cada variable.

```{r Solucion_Ej2, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}

View(Datos)
# 
# Datos %>% arrange(Age) %>% head()
# 
# Datos %>% arrange(desc(Age)) %>% head()
# 
# Datos %>% arrange(Wr.Hnd) %>% head()
# 
# Datos %>% arrange(desc(Wr.Hnd)) %>% head()

#asi con todas las variables o abrimos view y las vamos ordenando desde el header de la variable
```

# Análisis univariante de variables numéricas

## Ejercicio 3: Estadísticos básicos

Empleando la función `sumarise(across())` calcula la media, la desviación típica, mediana y el _interquartile range_ (`IQR`) de las variables que acaban en `.num` (notas numéricas).

    Ten en cuenta que no se puede realizar un análisis estadístico con datos faltantes, pero en la mayoría de los casos se puede optar por no considerar dichos valores al realizar los cálculos (`na.rm=TRUE`).
    Reordena los resultados para generar una tabla en la que tengas en cada fila una de las variables y en cada columna los estadísticos calculados.
  
    1. Primero usa `pivot_longer` para juntar todo en dos columnas, una para los nombres combinados de las variables y sus estadísticos, y otra para los valores.
    2. Luego usa `separate` para separar la columna de nombres en dos, una llamada `asignatura` con el nombre de la variable, y otra llamada `stat` con el nombre del estadístico.
    3. Por último, usa `pivot_wider` para distribuir la columna `stat` en cuatro columnas, cada una con el nombre del estadístico.
    4. Por último, combina las columnas que almacenan media y desviación típica en una columna, tipo texto, `mean`±`sd`. 

 Expresa los resultados con 2 decimales .

El resultado final debe ser una tabla como ésta:

asignatura | mean±sd | median | IQR
----|------|----|----
ALG.num|
ANM.num|
etc    |


```{r Solucion_Ej3, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}

# 1. Usar summarise(across()) para calcular los estadísticos de las columnas .num
Stats <- Datos %>%
  summarise(across(
    ends_with(".num"),
    list(
      mean = ~ mean(., na.rm = TRUE),
      sd = ~ sd(., na.rm = TRUE),
      median = ~ median(., na.rm = TRUE),
      IQR = ~ IQR(., na.rm = TRUE)
    )
  ))

# 2. Reordenar los resultados en el formato de tabla 
Stats_table <- Stats %>%
  # 1. Pivot_longer
  pivot_longer(
    cols = everything(),
    names_to = "name",
    values_to = "value"
  ) %>%
  # 2. Separate
  separate(name, into = c("asignatura", "stat"), sep = "_") %>%
  # 3. Pivot_wider
  pivot_wider(
    names_from = stat,
    values_from = value
  ) %>%
  # 4. Formatear y combinar columnas
  mutate(
    # Primero, formateamos todos los números a 2 decimales
    across(c(mean, sd, median, IQR), ~ format(round(., 2), nsmall = 2)),
    
    # Segundo, creamos la columna 'mean±sd' combinando las formateadas
    `mean±sd` = paste0(mean, "±", sd)
  ) %>%
  # Finalmente, seleccionamos las columnas en el orden deseado
  select(asignatura, `mean±sd`, median, IQR)

# Imprimimos la tabla final con kable() para un formato limpio
print(Stats_table)
```

## Ejercicio 4: Distribución de datos

Representa gráficamente la curva de notas de la asignatura ALG estimando la distribución de datos: histograma (`geom_histogram`) y curva de densidad (`geom_density`).

  - Recuerda que para que los dos representaciones 'casen' hay que indicarle a `geom_histogram` que use la función `density` para estimar el histograma, es decir: `geom_histogram(aes(y=stat(density)))`.
  - Compara el resultado con la media de las notas para esa asignatura. Puedes marcar dicha media en el gráfico con `geom_point` o con `geom_vline()` especificando el parámetro `xintercept`.

```{r Solucion_Ej4, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}
# Calculamos la media de ALG.num, ignorando los valores NA
mean_alg <- mean(Datos$ALG.num, na.rm = TRUE)

# Creamos el gráfico combinado
ggplot(Datos, aes(x = ALG.num)) +
  # 1. Histograma, indicando que el eje Y debe ser la densidad
  geom_histogram(
    aes(y = after_stat(density)),
    binwidth = 1,       # Ancho de bin de 1, apropiado para notas
    fill = "lightblue", # Color de relleno
    color = "black",    # Color del borde
    alpha = 0.7         # Transparencia
  ) +
  
  # 2. Curva de densidad
  geom_density(
    color = "red",  # Color de la línea
    linewidth = 1   # Grosor de la línea 
  ) +
  
  # 3. Línea vertical para la media 
  geom_vline(
    xintercept = mean_alg,
    color = "blue",
    linetype = "dashed", 
    linewidth = 1.2
  ) +
  
  # Añadimos títulos y etiquetas para claridad
  labs(
    title = "Distribución de Notas de Álgebra (ALG.num)",
    subtitle = "Histograma y Curva de Densidad",
    x = "Nota",
    y = "Densidad",
    caption = paste("La línea azul discontinua marca la media:", round(mean_alg, 2))
  ) +
  theme_minimal() 
```

## Ejercicio 5: Test de normalidad de la distribución de datos

Compara la distribución de probabilidad de las notas de la asignatura ANM con la de una Gaussiana empleando la función `qqPlot` (quantile-quantile plot) de la librería `car`, que representa gráficamente los cuantiles de la distribución analizada respecto de los de una distribución normal (Gaussiana).

```{r Solucion_Ej5, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}
# 1. Cargar la librería 'car' que contiene la función qqPlot
library(car)


# 2. Generar el Gráfico Q-Q (Quantile-Quantile)
# Esta función compara los cuantiles de nuestros datos (ANM.num)
# con los cuantiles de una distribución normal teórica.
# La función maneja los NAs por defecto (na.rm = TRUE)
qqPlot(Datos$ANM.num,
       main = "Q-Q Plot para Notas de ANM.num vs. Distribución Normal",
       xlab = "Cuantiles Teóricos (Normal)",
       ylab = "Cuantiles de la Muestra (ANM.num)",
       id = FALSE # Oculta la identificación de puntos atípicos
)

# Interpretación:
# Si los puntos (círculos) caen en su mayoría sobre la línea central continua
# y dentro de las bandas de confianza (líneas discontinuas),
# podemos asumir que los datos se aproximan a una distribución normal.
# Puntos que se desvían sistemáticamente o caen fuera de las bandas
# sugieren que los datos no son normalmente distribuidos.
```

# Análisis univariante de variables categóricas

## Ejercicio 6: Análisis de frecuencias en variables categóricas

Vamos a calcular la frecuencia de cada valor en las variables categóricas de calificaciones con la función `table`.

    Calcula la frecuencia de cada calificación para la asignatura ALG.
    Usa también la función `table` para calcular la tabla de contingencia con la frecuencia de cada combinación de las calificaciones de las asignaturas ALG y ANM.
    Representa la tabla de contingencia usando `mosaicplot`.

```{r Solucion_Ej6, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}
# 1. Calcula la frecuencia de cada calificación para la asignatura ALG
tabla_alg <- table(Datos$ALG.cat)
print("Frecuencias para ALG.cat:")
print(tabla_alg)

# 2. Calcula la tabla de contingencia para ALG y ANM
tabla_contingencia <- table(Datos$ALG.cat, Datos$ANM.cat)
print("Tabla de contingencia ALG.cat vs ANM.cat:")
print(tabla_contingencia)

# 3. Representa la tabla de contingencia usando mosaicplot
mosaicplot(tabla_contingencia,
           main = "Mosaic Plot de Calificaciones ALG vs ANM",
           xlab = "ALG.cat",
           ylab = "ANM.cat",
           color = TRUE, # Añade color para diferenciar las categorías
           las = 1      # Asegura que las etiquetas del eje Y sean horizontales
)
```

# Análisis bivariante de variables numéricas

## Ejercicio 7: Matrices de covarianza y correlación

    Calcula las matrices de covarianza (no acotada) y correlación (acotada), considerando todas las variables con las notas numéricas, para encontrar relaciones (lineales) entre variables. 
    Compara los resultados para el coeficiente de correlación de Pearson (para variables numéricas) y de Spearman (para variables numéricas ordinales).

```{r Solucion_Ej7, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}
# 1. Seleccionar solo las variables de notas numéricas
notas_num <- Datos %>%
  select(ends_with(".num"))

# 2. Calcular la Matriz de Covarianza
# Usamos 'pairwise.complete.obs' para manejar los NAs,
# calculando la covarianza para cada par de variables usando
# solo las filas donde ambas tienen valores.
matriz_cov <- cov(notas_num, use = "pairwise.complete.obs")

print("--- Matriz de Covarianza ---")
print(round(matriz_cov, 2))

# 3. Calcular la Matriz de Correlación de Pearson
# Mismo manejo de NAs. Pearson mide la relación  lineal .
matriz_cor_pearson <- cor(notas_num, method = "pearson", use = "pairwise.complete.obs")

print("--- Matriz de Correlación de Pearson (Lineal) ---")
print(round(matriz_cor_pearson, 2))

# 4. Calcular la Matriz de Correlación de Spearman
# Mismo manejo de NAs. Spearman mide la relación  monotónica 
# (si una variable aumenta, la otra también aumenta o disminuye,
# pero no necesariamente de forma lineal).
matriz_cor_spearman <- cor(notas_num, method = "spearman", use = "pairwise.complete.obs")

print("--- Matriz de Correlación de Spearman (Monotónica) ---")
print(round(matriz_cor_spearman, 2))

# 5. Comparación
#
#   La   Matriz de Covarianza   muestra la dirección de la relación (positiva o
#   negativa), pero su magnitud es difícil de interpretar porque depende
#   de la escala de las variables (ej. cov(ALG, ANM) = 4.79).
#   La   Matriz de Correlación de Pearson   normaliza la covarianza a un
#   rango de [-1, 1]. Vemos correlaciones lineales positivas fuertes
#   (ej. ALG y ANM tienen 0.81), lo que indica que a notas más altas
#   en una, tienden a corresponder notas más altas en la otra de forma lineal.
#   La   Matriz de Correlación de Spearman   es similar, pero se basa en
#   los rangos de las notas. Los valores (ej. ALG y ANM tienen 0.82)
#   son muy parecidos a los de Pearson, lo que sugiere que las
#   relaciones monotónicas observadas son, de hecho, bastante lineales.
#   Si Spearman fuera mucho más alto que Pearson, indicaría una
#   relación monotónica fuerte pero no lineal.
```

La correlación de Pearson sirve para cuando la relación entre dos variables es lineal, mientras que la de Spearman es robusta frente a relaciones no lineales en datos ordenados.

  Nota  :(La correlación de Spearman calcula la correlación entre los rangos de las secuencias. El rango de una secuencia es otra secuencia de la misma longitud cuyos valores son las  posiciones que ocuparía el valor de la variable original cuando la secuencia de partida se ordena en orden creciente, por ejmplo, si aa<-c(1,3.8,5,2.3), rank(aa) es la secuencia (1,3,4,2), ya que estas serían las posiciones en la secuencia ordenada de los valores de la secuencia inicial.). Cualquier función creciente (lineal o no lineal), aplicada sobre los datos no modifica el resultado de la correlación de Spearman.

Para comprobarlo, vamos a aplicar una función no lineal a una de las variables y a calcular la correlación usando los métodos de Pearson y Spearman. Compruébalo entre las variables `sqrt(ALG.num)` y `MD.num`, comparando con los resultados anteriores. 

```{r Solucion_Ej7 bis, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}

# 1. Obtenemos las correlaciones originales entre ALG.num y MD.num
original_pearson <- matriz_cor_pearson["ALG.num", "MD.num"]
original_spearman <- matriz_cor_spearman["ALG.num", "MD.num"]

cat("--- Correlaciones Originales (ALG.num vs MD.num) ---\n")
cat(paste("Pearson Original:  ", round(original_pearson, 4), "\n"))
cat(paste("Spearman Original: ", round(original_spearman, 4), "\n\n"))


# 2. Calculamos las nuevas correlaciones con la variable transformada sqrt(ALG.num)

# Nuevo Pearson: sqrt(ALG.num) vs MD.num
# La función cor() maneja la transformación 'sqrt()' sobre la marcha
new_pearson <- cor(sqrt(Datos$ALG.num), Datos$MD.num,
                   method = "pearson",
                   use = "pairwise.complete.obs")
                   
# Nuevo Spearman: sqrt(ALG.num) vs MD.num
new_spearman <- cor(sqrt(Datos$ALG.num), Datos$MD.num,
                    method = "spearman",
                    use = "pairwise.complete.obs")

cat("--- Correlaciones con Transformación (sqrt(ALG.num) vs MD.num) ---\n")
cat(paste("Pearson (Transformado):  ", round(new_pearson, 4), "\n"))
cat(paste("Spearman (Transformado): ", round(new_spearman, 4), "\n\n"))


# 3. Conclusión
cat("--- Comparación y Conclusión ---\n")
cat(paste(
  "El coeficiente de Pearson CAMBIÓ (de", round(original_pearson, 4), "a", round(new_pearson, 4), 
  ") porque la transformación de raíz cuadrada (y = sqrt(x)) no es lineal, y Pearson mide solo la relación  lineal .\n"
))
cat(paste(
  "El coeficiente de Spearman NO CAMBIÓ (", round(original_spearman, 4), "vs", round(new_spearman, 4), 
  ") porque la raíz cuadrada es una función  monotónica creciente . Esto significa que si X1 > X2, entonces sqrt(X1) > sqrt(X2). Como Spearman solo se basa en el  ranking  (la posición ordenada) de los datos, y el ranking no cambia con una transformación monotónica, la correlación de Spearman permanece idéntica.\n"
))
```

## Ejercicio 8: Representación gráfica de correlación entre variables

Dibuja las matrices de correlación del conjunto de notas numéricas.
Podemos usar `pairs` del paquete base o bien `ggcorr` y `ggpairs` de la librería `GGally`.

```{r Solucion_Ej8, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}
# 1. Seleccionar solo las variables de notas numéricas
notas_num <- Datos %>%
  select(ends_with(".num"))

# --- Plot 1: pairs (Base R) ---
# Muestra una matriz de gráficos de dispersión (scatterplot matrix).
# Es útil para ver la forma de la relación (lineal, curva, etc.).
cat("--- 1. Gráfico 'pairs' (Base R) ---\n")
pairs(notas_num,
      main = "Matriz de Dispersión (Base R pairs)",
      pch = 19, 
      col = alpha("blue", 0.5) 
)


# --- Plot 2: ggcorr (GGally) ---
# Muestra una matriz de correlación (heatmap).
# Es excelente para ver la  magnitud  y  dirección  de la correlación
# de un vistazo usando colores.
cat("\n--- 2. Gráfico 'ggcorr' (GGally) ---\n")
print(
  ggcorr(
    notas_num,
    method = c("pairwise", "pearson"), # Método (consistente con Ej7)
    label = TRUE,                  # Añadir valores numéricos
    label_round = 2,               # Redondear a 2 decimales
    hjust = 0.75,                  # Ajuste horizontal de la etiqueta
    size = 3,                      # Tamaño de la etiqueta
    color = "grey50",              # Color del texto de la etiqueta
    layout.exp = 1                 # Expande el layout
  ) +
    labs(title = "Matriz de Correlación (ggcorr)")
)
# 

# --- Plot 3: ggpairs (GGally) ---
# Es la visualización más completa. Combina:
# - Diagonal: Distribución (densidad) de cada variable.
# - Triángulo inferior: Gráficos de dispersión (como 'pairs').
# - Triángulo superior: Valores de correlación (como 'ggcorr').

cat("\n--- 3. Gráfico 'ggpairs' (GGally) ---\n")
print(
  ggpairs(
    notas_num,
    title = "Matriz de Pares (ggpairs)",
    progress = FALSE, # Ocultar barra de progreso
    upper = list(continuous = wrap("cor", method = "pearson", size = 4)), # Correlación arriba
    lower = list(continuous = wrap("points", alpha = 0.5, size = 1.5)) # Puntos abajo
  )
)
#
```

# Análisis bivariante de variables categóricas

## Ejercicio 9: Dependencia entre variables categóricas

Vamos a considerar 2 variables categóricas para determinar su relación en términos de dependencia con el test Chi cuadrado de Pearson ($\chi^2$).

    Comprueba la dependencia entre los tipos de calificaciones de ALG y ANM.
    Comprueba si existe dependencia entre la calificación de ALG y la variable Sex.

Nota: usa la función `chisq.test` con el parámetro `correct=FALSE` y analiza su significancia estadística (si $p<0,05$ rechazamos la hipótesis nula de independencia y concluimos que existe dependencia entre las variables). 

```{r Solucion_Ej9, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}
# Comprobación de dependencia entre ALG.cat y ANM.cat

# 1. Realizamos el test Chi-cuadrado
# H0 (Hipótesis Nula): Las calificaciones de ALG y ANM son independientes.
# H1 (Hipótesis Alternativa): Las calificaciones de ALG y ANM son dependientes.
test_alg_anm <- chisq.test(Datos$ALG.cat, Datos$ANM.cat, correct = FALSE)

print(test_alg_anm)

# 3. Interpretación:

# Dado que p-value (<< 0.05) es menor que el nivel de significancia 0.05,
# rechazamos la hipótesis nula (H0).
#
# Conclusión: Existe una dependencia estadística significativa entre
# las calificaciones obtenidas en ALG y ANM. (Lo cual es esperable).
```


```{r Solucion_Ej9b, include=TRUE, echo=TRUE, eval=TRUE, results=TRUE}
# Comprobación de dependencia entre ALG.cat y Sex

# 1. Realizamos el test Chi-cuadrado
# H0 (Hipótesis Nula): La calificación de ALG y el Sexo son independientes.
# H1 (Hipótesis Alternativa): La calificación de ALG y el Sexo son dependientes.
test_alg_sex <- chisq.test(Datos$ALG.cat, Datos$Sex, correct = FALSE)

print(test_alg_sex)

# El resultado muestra un p-valor (p-value) muy alto.
#
# Dado que el p-value es mayor que 0.05, no podemos rechazar
# la hipótesis nula (H0) de independencia.
#
# Conclusión: No encontramos evidencia estadística suficiente para
# afirmar que exista dependencia entre la calificación de ALG y el Sexo.

```




